<!DOCTYPE html>
<html lang="en">
    <head>
        <title>Ximing Lu</title>
        <meta http-equiv="content-type" content="text/html; charset=UTF-8" />
        <meta charset="utf-8" />
        <meta property="og:title" content="Ximing Lu" />
        <meta property="og:image" content="https://ximinglu1999.github.io/img/ximing.jpg" />
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="author" content="Ximing Lu" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <link rel="shortcut icon" type="image/png" href="favicon.ico" />

        <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous" />
        <link rel="stylesheet" href="css/style.css" />
        <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
        <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
    </head>
    <body>
        <style>
            pre {
                text-align: left;
                white-space: pre-line;
            }
        </style>
        <div class="container mt-5">
            <div class="row mb-3">
                <div class="col">
                    <h1>Ximing Lu</h1>
                </div>
            </div>
            <div class="row">
                <div class="col-md-4 order-md-2">
                    <img src="img/ximing.jpg" alt="Ximing" class="img-fluid rounded" />
                </div>
                <div class="col-md-8 order-md-1">
                    <p>
                        I am a Ph.D. student working on Natural Language Processing and Artificial Intelligence at the <a href="https://www.cs.washington.edu/">University of Washington</a> and <a href="https://allenai.org/">Allen Institute for AI</a>, advised by Professor <a href="https://homes.cs.washington.edu/~yejin/" target="_blank">Yejin Choi</a>. Previously, I received my B.S. degree in Computer Science at University of Washington.
                    </p>
                    <p>
                        My broad research goal is to <b>understand the boundaries</b> of machine intelligence and <b>bridge the capability gap</b> between models and humans by exploring alternative paths beyond scaling, such as algorithmic innovations and knowledge enhancement.
                        Over the past few years, I have focused on <b>studying the capabilities and limits</b> of language models, as well as <b>developing learning and inference algorithms</b> to unlock capabilities in smaller models, for example:
                    </p>
                    <ul>
                        <li>I investigate the fundamental limits of Transformer language models in the context of compositional tasks in my work <a href="https://arxiv.org/abs/2305.18654">Faith and Fate</a>. I explore the divergence in the configuration of machine and human intelligence by proposing and testing the <a href="https://arxiv.org/abs/2311.00059">Generative AI Paradox</a>.</li>
                        <li>I have worked to develop a suite of learning and decoding-time methods to empower compact and efficient LMs, including <a href="https://arxiv.org/abs/2010.12884">NeuroLogic Decoding</a>, <a href="https://arxiv.org/abs/2112.08726">NeuroLogic A<sup>*</sup>esque Decoding</a>, <a href="https://arxiv.org/abs/2205.13636">Quark</a>, and <a href="https://arxiv.org/abs/2305.15065">Inference-Time Policy Adapters</a>.</li>
                    </ul> 
                    <p>
                    I am happy to mentor a few self-motivated undergraduate and master students. Please feel free to reach out if you are interested in working with me!
                    </p>
                    <p>Email: lux32 [<a href="https://en.wikipedia.org/wiki/At_sign" target="_blank">at</a>] cs.washington.edu</p>
                    <p>Links: [<a href="https://scholar.google.com/citations?user=ssYPSmkAAAAJ&hl=en" target="_blank">Google Scholar</a>] [<a href="https://twitter.com/gximing?lang=en" target="_blank">Twitter</a>] [<a href="https://github.com/GXimingLu" target="_blank">Github</a>] [CV] [<a href="img/Research_Statement.pdf" target="_blank">Research Statement</a>]</p>
                </div>
            </div>
            <hr />
            <div class="row" id="publications">
                <div class="col">
                    <h2>Publications</h2>
                    <p>Publications are listed in reverse chronological order. For a list of all publications, please check out my <a href="https://scholar.google.com/citations?user=ssYPSmkAAAAJ&hl=en" target="_blank">Google Scholar</a></p>
                    <ul>
                        <li>
                            <a href="https://ojs.aaai.org/index.php/AAAI/article/view/29970"><b>Value Kaleidoscope: Engaging AI with Pluralistic Human Values, Rights, and Duties</b></a><br>
                            Taylor Sorensen, Liwei Jiang, Jena D Hwang, Sydney Levine, Valentina Pyatkin, Peter West, Nouha Dziri, <strong>Ximing Lu</strong>, Kavel Rao, Chandra Bhagavatula, Maarten Sap, John Tasioulas, Yejin Choi
                            <br>
                            In AAAI 2024 <br>
                            [bib][abstract][arxiv]
                        </li>
                        <li>
                            <a href="https://arxiv.org/abs/2403.13780"><b>Information-Theoretic Distillation for Reference-less Summarization</b></a><br>
                            Jaehun Jung, <strong>Ximing Lu</strong>, Liwei Jiang, Faeze Brahman, Peter West, Pang Wei Koh, Yejin Choi<br>
                            arXiv preprint arXiv:2403.13780, 2024 <br>
                            [bib][abstract][arxiv]
                        </li>
                        <li>
                            <b><a href="https://arxiv.org/abs/2402.08761">JAMDEC: Unsupervised Authorship Obfuscation using Constrained Decoding over Small Language Models</b></a><br> 
                            Jillian Fisher, <strong>Ximing Lu</strong>, Jaehun Jung, Liwei Jiang, Zaid Harchaoui, Yejin Choi<br>
                            In NAACL 2024 <br>
                            [bib][abstract][arxiv]
                        </li>
                        <li>
                            <b><a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/257be12f31dfa7cc158dda99822c6fd1-Abstract-Conference.html">Localized Symbolic Knowledge Distillation for Visual Commonsense Models</b></a><br>
                            Jae Sung Park, Jack Hessel, Khyathi Chandu, Paul Pu Liang, <strong>Ximing Lu</strong>, Peter West, Youngjae Yu, Qiuyuan Huang, Jianfeng Gao, Ali Farhadi, Yejin Choi<br>
                            In NeurIPS 2023 <br>
                            [bib][abstract]
                        </li>
                        <li>
                            <a href="https://proceedings.neurips.cc/paper_files/paper/2023/hash/deb3c28192f979302c157cb653c15e90-Abstract-Conference.html"><b>Faith and Fate: Limits of Transformers on Compositionality</b></a><br>
                            Nouha Dziri, <strong>Ximing Lu</strong>*, Melanie Sclar, Xiang (Lorraine) Li, Liwei Jiang, Bill Yuchen Lin, Sean Welleck, Peter West, Chandra Bhagavatula, Ronan Le Bras, Jena Hwang, Soumya Sanyal, Xiang Ren, Allyson Ettinger, Zaid Harchaoui, Yejin Choi<br>
                            <b style="color:#FF0000" ;=""> Spotlight Paper at NeurIPS 2023 </b><br>
                            [bib][abstract]
                        </li>
                        <li>
                            <a href="https://arxiv.org/abs/2402.05070"><b>A Roadmap to Pluralistic Alignment</b></a><br>
                            Taylor Sorensen, Jared Moore, Jillian Fisher, Mitchell Gordon, Niloofar Mireshghallah, Christopher Michael Rytting, Andre Ye, Liwei Jiang, <strong>Ximing Lu</strong>, Nouha Dziri, Tim Althoff, Yejin Choi<br>
                            To Appear In ICML 2024 <br>
                            [bib][abstract]
                        </li>
                        <li>
                            <a href="https://arxiv.org/abs/2312.05979"><b>NovaCOMET: Open Commonsense Foundation Models with Symbolic Knowledge Distillation</b></a><br>
                            Peter West, Ronan Le Bras, Taylor Sorensen, Bill Yuchen Lin, Liwei Jiang, Ximing Lu, Khyathi Chandu, Jack Hessel, Ashutosh Baheti, Chandra Bhagavatula, Yejin Choi <br>
                            Findings of EMNLP 2023 <br>
                            [bib][abstract]
                        </li>
                        <li>
                            <a href="https://arxiv.org/abs/2312.01552"><b>The Unlocking Spell on Base LLMs: Rethinking Alignment via In-Context Learning</b></a><br>
                            Bill Yuchen Lin, Abhilasha Ravichander, Ximing Lu, Nouha Dziri, Melanie Sclar, Khyathi Chandu, Chandra Bhagavatula, Yejin Choi<br>
                            ICLR 2024 <br>
                            [bib][abstract]
                        </li>
                        <li>
                            <a href="https://aclanthology.org/2023.emnlp-main.424/"><b>Inference-time Policy Adapters (IPA): Tailoring Extreme-Scale LMs Without Fine-Tuning</b></a><br>
                            Ximing Lu, Faeze Brahman, Peter West, Jaehun Jung, Khyathi Chandu, Abhilasha Ravichander, Prithviraj Ammanabrolu, Liwei Jiang, Sahana Ramnath, Nouha Dziri, Jillian Fisher, Bill Lin, Skyler Hallinan, Lianhui Qin, Xiang Ren, Sean Welleck, Yejin Choi <br>
                            EMNLP 2023 <br>
                            [bib][abstract]
                        </li>
                        <li>
                            <a href="https://arxiv.org/abs/2311.07237"><b>In Search of the Long-Tail: Systematic Generation of Long-Tail Knowledge via Logical Rule Guided Search</b></a><br>
                            Huihan Li, Yuting Ning, Zeyi Liao, Siyuan Wang, Xiang Lorraine Li, Ximing Lu, Wenting Zhao, Faeze Brahman, Yejin Choi, Xiang Ren<br>
                            arXiv preprint 2023 <br>
                            [bib][abstract]
                        </li>
                        <li>
                            <a href="https://arxiv.org/abs/2311.07167"><b>STEER: Unified Style Transfer with Expert Reinforcement</b></a><br>
                            Skyler Hallinan, Faeze Brahman, Ximing Lu, Jaehun Jung, Sean Welleck, Yejin Choi <br>
                            Findings of EMNLP 2023 <br>
                            [bib][abstract]
                        </li>
                        <li>
                            <a href="https://arxiv.org/abs/2311.02805"><b>Tailoring Self-Rationalizers with Multi-Reward Distillation</b></a><br>
                            Sahana Ramnath, Brihi Joshi, Skyler Hallinan, Ximing Lu, Liunian Harold Li, Aaron Chan, Jack Hessel, Yejin Choi, Xiang Ren<br>
                            ICLR 2024 <br>
                            [bib][abstract]
                        </li>
                        <li>
                            <a href="https://arxiv.org/abs/2311.00059"><b>THE GENERATIVE AI PARADOX: “What It Can Create, It May Not Understand”</b></a><br>
                            Peter West, Ximing Lu, Nouha Dziri, Faeze Brahman, Linjie Li, Jena D. Hwang, Liwei Jiang, Jillian Fisher, Abhilasha Ravichander, Khyathi Chandu, Benjamin Newman, Pang Wei Koh, Allyson Ettinger, Yejin Choi<br>
                            ICLR 2024 <br>
                            [bib][abstract]
                        </li>
                        <li>
                            <a href="https://arxiv.org/abs/2310.08559"><b>Phenomenal Yet Puzzling: Testing Inductive Reasoning Capabilities of Language Models with Hypothesis Refinement</b></a><br>
                            Linlu Qiu, Liwei Jiang, Ximing Lu, Melanie Sclar, Valentina Pyatkin, Chandra Bhagavatula, Bailin Wang, Yoon Kim, Yejin Choi, Nouha Dziri, Xiang Ren<br>
                            ICLR 2024 <br>
                            [bib][abstract]
                        </li>
                        <li>
                            <a href="https://arxiv.org/abs/2305.16635"><b>Impossible Distillation: From Low-Quality Model to High-Quality Dataset & Model for Summarization and Paraphrasing</b></a><br>
                            Jaehun Jung, Peter West, Liwei Jiang, Faeze Brahman, Ximing Lu, Jillian Fisher, Taylor Sorensen, Yejin Choi<br>
                            NAACL 2024 <br>
                            [bib][abstract]
                        </li>
                        <li>
                            <a href="https://arxiv.org/abs/2305.14718"><b>Improving Language Models with Advantage-Based Offline Policy Gradients</b></a><br>
                            Ashutosh Baheti, Ximing Lu, Faeze Brahman, Ronan Le Bras, Maarten Sap, Mark Riedl<br>
                            ICLR 2024 <br>
                            [bib][abstract]
                        </li>
                        <li>
                            <a href="https://openaccess.thecvf.com/content/CVPR2023/html/Yu_Fusing_Pre-Trained_Language_Models_With_Multimodal_Prompts_Through_Reinforcement_Learning_CVPR_2023_paper.html"><b>Fusing Pre-trained Language Models with Multimodal Prompts Through Reinforcement Learning</b></a><br>
                            Youngjae Yu, Jiwan Chung, Heeseung Yun, Jack Hessel, Jae Sung Park, Ximing Lu, Rowan Zellers, Prithviraj Ammanabrolu, Ronan Le Bras, Gunhee Kim, Yejin Choi<br>
                            CVPR 2023 <br>
                            [bib][abstract]
                        </li>
                        <li>
                            <a href="https://arxiv.org/abs/2212.10409"><b>ClarifyDelphi: Reinforced Clarification Questions with Defeasibility Rewards for Social and Moral Situations</b></a><br>
                            Valentina Pyatkin, Jena D. Hwang, Vivek Srikumar, Ximing Lu, Liwei Jiang, Yejin Choi, Chandra Bhagavatula<br>
                            arXiv preprint arXiv:2212.10409, 2022<br>
                            [bib][abstract]
                        </li>
                        <li>
                            <b>Soda: Million-scale Dialogue Distillation with Social Commonsense Contextualization</b> - H Kim, J Hessel, L Jiang, P West, X Lu, Y Yu, P Zhou, RL Bras, M Alikhani, et al.<br>
                            arXiv preprint arXiv:2212.10465, 2022
                        </li>
                        <li>
                            <b>I2D2: Inductive Knowledge Distillation with Neurologic and Self-Imitation</b> - C Bhagavatula, JD Hwang, D Downey, RL Bras, X Lu, L Qin, K Sakaguchi, et al.<br>
                            arXiv preprint arXiv:2212.09246, 2022
                        </li>
                        <li>
                            <b>Quark: Controllable Text Generation with Reinforced Unlearning</b> - X Lu, S Welleck, J Hessel, L Jiang, L Qin, P West, P Ammanabrolu, Y Choi<br>
                            Advances in Neural Information Processing Systems 35, 27591-27609, 2022
                        </li>
                        <li>
                            <b>Naturalprover: Grounded Mathematical Proof Generation with Language Models</b> - S Welleck, J Liu, X Lu, H Hajishirzi, Y Choi<br>
                            Advances in Neural Information Processing Systems 35, 4913-4927, 2022
                        </li>
                        <li>
                            <b>Generating Sequences by Learning to Self-Correct</b> - S Welleck, X Lu, P West, F Brahman, T Shen, D Khashabi, Y Choi<br>
                            arXiv preprint arXiv:2211.00053, 2022
                        </li>
                        <li>
                            <b>Rainier: Reinforced Knowledge Introspector for Commonsense Question Answering</b> - J Liu, S Hallinan, X Lu, P He, S Welleck, H Hajishirzi, Y Choi<br>
                            arXiv preprint arXiv:2210.03078, 2022
                        </li>
                        <li>
                            <b>End-to-End Diagnosis of Breast Biopsy Images with Transformers</b> - S Mehta, X Lu, W Wu, D Weaver, H Hajishirzi, JG Elmore, LG Shapiro<br>
                            Medical Image Analysis 79, 102466, 2022
                        </li>
                        <li>
                            <b>Prosocialdialog: A Prosocial Backbone for Conversational Agents</b> - H Kim, Y Yu, L Jiang, X Lu, D Khashabi, G Kim, Y Choi, M Sap<br>
                            arXiv preprint arXiv:2205.12688, 2022
                        </li>
                        <li>
                            <b>Twist Decoding: Diverse Generators Guide Each Other</b> - J Kasai, K Sakaguchi, RL Bras, H Peng, X Lu, D Radev, Y Choi, NA Smith<br>
                            arXiv preprint arXiv:2205.09273, 2022
                        </li>
                        <li>
                            <b>Reinforced Clarification Question Generation with Defeasibility Rewards for Disambiguating Social and Moral Situations</b> - V Pyatkin, JD Hwang, V Srikumar, X Lu, L Jiang, Y Choi, C Bhagavatula<br>
                            arXiv preprint arXiv:2212.10409, 2022
                        </li>
                        <li>
                            <b>Merlot Reserve: Neural Script Knowledge Through Vision and Language and Sound</b> - R Zellers, J Lu, X Lu, Y Yu, Y Zhao, M Salehi, A Kusupati, J Hessel, et al.<br>
                            Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition, 2022
                        </li>
                        <li>
                            <b>Connecting the Dots Between Audio and Text Without Parallel Data Through Visual Knowledge Transfer</b> - Y Zhao, J Hessel, Y Yu, X Lu, R Zellers, Y Choi<br>
                            arXiv preprint arXiv:2112.08995, 2021
                        </li>
                        <li>
                            <b>Neurologic A* Esque Decoding: Constrained Text Generation with Lookahead Heuristics</b> - X Lu, S Welleck, P West, L Jiang, J Kasai, D Khashabi, RL Bras, L Qin, et al.<br>
                            arXiv preprint arXiv:2112.08726, 2021
                        </li>
                        <li>
                            <b>Merlot: Multimodal Neural Script Knowledge Models</b> - R Zellers, X Lu, J Hessel, Y Yu, JS Park, J Cao, A Farhadi, Y Choi<br>
                            Advances in Neural Information Processing Systems 34, 23634-23651, 2021
                        </li>
                        <li>
                            <b>Generated Knowledge Prompting for Commonsense Reasoning</b> - J Liu, A Liu, X Lu, S Welleck, P West, RL Bras, Y Choi, H Hajishirzi<br>
                            arXiv preprint arXiv:2110.08387, 2021
                        </li>
                        <li>
                            <b>Symbolic Knowledge Distillation: From General Language Models to Commonsense Models</b> - P West, C Bhagavatula, J Hessel, JD Hwang, L Jiang, RL Bras, X Lu, et al.<br>
                            arXiv preprint arXiv:2110.07178, 2021
                        </li>
                        <li>
                            <b>Analysis of Regions of Interest and Distractor Regions in Breast Biopsy Images</b> - X Lu, S Mehta, TT Brunyé, DL Weaver, JG Elmore, LG Shapiro<br>
                            2021 IEEE EMBS International Conference on Biomedical and Health Informatics, 2021
                        </li>
                        <li>
                            <b>Neurologic Decoding: (Un)Supervised Neural Text Generation with Predicate Logic Constraints</b> - X Lu, P West, R Zellers, RL Bras, C Bhagavatula, Y Choi<br>
                            Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics, 2021
                        </li>
                        <li>
                            <b>DExperts: Decoding-Time Controlled Text Generation with Experts and Anti-Experts</b> - A Liu, M Sap, X Lu, S Swayamdipta, C Bhagavatula, NA Smith, Y Choi<br>
                            arXiv preprint arXiv:2105.03023, 2021
                        </li>
                        <li>
                            <b>On-the-Fly Attention Modulation for Neural Generation</b> - Y Dong, C Bhagavatula, X Lu, JD Hwang, A Bosselut, JCK Cheung, et al.<br>
                            arXiv preprint arXiv:2101.00371, 2021
                        </li>
                        <li>
                            <b>Analyzing Commonsense Emergence in Few-Shot Knowledge Models</b> - J Da, RL Bras, X Lu, Y Choi, A Bosselut<br>
                            arXiv preprint arXiv:2101.00297, 2021
                        </li>
                        <li>
                            <b>Applications of the ESPNet Architecture in Medical Imaging</b> - S Mehta, N Nuechterlein, E Mercan, B Li, S Nofallah, W Wu, X Lu, A Caspi, et al.<br>
                            State of the Art in Neural Networks and their Applications, 117-131, 2021
                        </li>
                        <li>
                            <b>Reflective Decoding: Beyond Unidirectional Generation with Off-the-Shelf Language Models</b> - P West, X Lu, A Holtzman, C Bhagavatula, J Hwang, Y Choi<br>
                            arXiv preprint arXiv:2010.08566, 2020
                        </li>
                    </ul>
                </div>
            </div>

            <hr />
            <div class="row">
                <div class="col">
                    <h2>Honors & Awards</h2>
                    <ul>
                        <li>
                            (2022) Best Paper Award at NAACL
                            <br>
                        </li>
                    </ul>
                </div>
            </div>
            <hr />
            <div class="row">
                <div class="col">
                    <h2>Teaching Experience</h2>
                    <ul>
                        <!-- Teaching experiences can be listed here -->
                        <li>
                            (2023) TA @ CSE 447/517 (Undergrad/Grad NLP) at University of Washington
                        </li>
                        <li>
                            (2021) TA @ CSE P517 (Professional NLP) at University of Washington
                        </li>
                    </ul>
                </div>
            </div>
            <footer class="pt-2 my-md-2 pt-md-2 border-top">
                <div class="row justify-content-center">
                    <div class="col-6 col-md text-left align-self-center">
                        <p class="h5 text-muted">
                            Ximing, 2024
                        </p>
                    </div>
                </div>
            </footer>
        </div>
    </body>
</html>
